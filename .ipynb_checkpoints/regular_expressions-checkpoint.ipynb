{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That said, learning (and loving!) regular expressions is something that is a worthwhile investment\n",
    "<ul>\n",
    "<li>Once you understand how they work, complex operations with string data can be written a lot quicker, which will save you time.</li>\n",
    "    <li>Regular expressions are often faster to execute than their manual equivalents.</li>\n",
    "<li>Regular expressions are supported in almost every modern programming language, as well as other places like command line utilities and databases. Understanding regular expressions gives you a powerful tool that you can use wherever you work with data.</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we will be working with is based off this CSV of Hacker News stories from September 2015 to September 2016. The columns in the dataset are explained below:\n",
    "<ul>\n",
    "    <li><b>id</b>: The unique identifier from Hacker News for the story</li>\n",
    "    <li><b>title</b>: The title of the story</li>\n",
    "    <li><b>url</b>: The URL that the stories links to, if the story has a URL</li>\n",
    "    <li><b>num_points</b>: The number of points the story acquired, calculated as the total number of upvotes minus the total number of downvotes</li>\n",
    "    <li><b>num_comments</b>: The number of comments that were made on the story</li>\n",
    "    <li><b>author</b>: The username of the person who submitted the story</li>\n",
    "    <li><b>created_at</b>: The date and time at which the story was submitted</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For teaching purposes, the dataset has been reduced from the almost 300,000 rows in its original form to approximately 20,000 rows by removing all submissions that did not receive any comments, and then randomly sampling from the remaining submissions. You can download the modified dataset using the dataset preview tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
